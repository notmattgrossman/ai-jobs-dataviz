Model,Year,Mean score
Mistral Instruct v0.1 (7B),2023,0.53
GPT-3.5 Turbo (0125),2023,0.81
GPT-3.5 Turbo (1106),2023,0.84
GPT-3.5 Turbo (0613),2023,0.85
DeepSeek LLM Chat (67B),2023,0.87
DBRX Instruct,2024,0.63
Mistral Instruct v0.3 (7B),2024,0.73
Command R,2024,0.81
Mixtral Instruct (8x7B),2024,0.81
Llama 3.1 Instruct Turbo (70B),2024,0.85
Mixtral Instruct (8x22B),2024,0.85
Command R Plus,2024,0.86
Llama 3.1 Instruct Turbo (8B),2024,0.86
DeepSeek v3,2024,0.87
Claude 3 Haiku (20240307),2024,0.88
Qwen1.5 Chat (72B),2024,0.89
Llama 3 Instruct (8B),2024,0.89
Llama 3 Instruct (70B),2024,0.90
Llama 3.1 Instruct Turbo (405B),2024,0.90
Gemini 1.5 Pro (001),2024,0.92
Gemini 1.5 Flash (001),2024,0.93
GPT-4o mini (2024-07-18),2024,0.93
Qwen2 Instruct (72B),2024,0.93
Claude 3 Sonnet (20240229),2024,0.94
GPT-4o (2024-05-13),2024,0.95
o1-mini (2024-09-12),2024,0.96
GPT-4 Turbo (2024-04-09),2024,0.96
Claude 3 Opus (20240229),2024,0.97
o1 (2024-12-17),2024,0.98
Claude 3.5 Sonnet (20240620),2024,0.98
DeepSeek R1,2025,0.87
DeepSeek R1 (hide reasoning),2025,0.87
o3-mini (2025-01-31),2025,0.96