% of respondents,Risk category,Year
30%,"Socio-environmental risks (e.g., high carbon footprint of systems, regional pollution)",2024
33%,"Societal risks (e.g., threats to political stability, national security concerns)",2024
34%,"Client/customer risks (e.g., loss of trust, market share, or customer satisfaction)",2024
29%,"Diversity and nondiscrimination risks (e.g., fairness concerns, toxicity, discrimination, and stereotype reproduction)",2024
35%,"Human interaction risks (e.g., misuse by users for the generation of deepfakes or misinformation, overreliance of users on AI models/systems, or physical/mental harm due to model/system usage)",2024
26%,"Brand/reputational risks (e.g., damage caused to brand by AI-related incident)",2024
12%,"Financial risks (e.g., lack of AI-related ROI, AI-related financial loss)",2024
47%,"Security risks (e.g., adversarial attacks, model theft)",2024
29%,"Compliance and lawfulness risks (e.g., IP or copyright violations)",2024
45%,"Reliability risks (e.g., output errors, hallucinations)",2024
51%,"Privacy and data-related risks (e.g., reidentification of anonymized data, data leakage, use of data without consent)",2024
22%,"Socio-environmental risks (e.g., high carbon footprint of systems, regional pollution)",2025
26%,"Societal risks (e.g., threats to political stability, national security concerns)",2025
32%,"Client/customer risks (e.g., loss of trust, market share, or customer satisfaction)",2025
35%,"Diversity and nondiscrimination risks (e.g., fairness concerns, toxicity, discrimination, and stereotype reproduction)",2025
40%,"Human interaction risks (e.g., misuse by users for the generation of deepfakes or misinformation, overreliance of users on AI models/systems, or physical/mental harm due to model/system usage)",2025
42%,"Brand/reputational risks (e.g., damage caused to brand by AI-related incident)",2025
50%,"Financial risks (e.g., lack of AI-related ROI, AI-related financial loss)",2025
52%,"Security risks (e.g., adversarial attacks, model theft)",2025
56%,"Compliance and lawfulness risks (e.g., IP or copyright violations)",2025
59%,"Reliability risks (e.g., output errors, hallucinations)",2025
65%,"Privacy and data-related risks (e.g., reidentification of anonymized data, data leakage, use of data without consent)",2025