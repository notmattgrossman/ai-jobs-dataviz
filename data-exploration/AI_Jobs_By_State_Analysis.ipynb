{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Jobs Market Analysis: State-by-State & Industry Deep Dive\n",
        "## 2025 AI Index Report Data\n",
        "\n",
        "This notebook analyzes AI employment by **US State** and **Industry Sector** to identify geographic hotspots and sectoral trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Libraries loaded and ready\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "data_path = Path('/Users/matthewgrossman/Desktop/PUBLIC DATA_ 2025 AI Index Report/4. Economy/Data')\n",
        "print(\"âœ“ Libraries loaded and ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. US State Analysis - AI Job Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/matthewgrossman/Desktop/PUBLIC DATA_ 2025 AI Index Report/4. Economy/Data/fig_4.2.10.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load US state AI job data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m us_states_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfig_4.2.10.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m us_states_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpct\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m us_states_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPercentage of US AI job postings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m us_states_df \u001b[38;5;241m=\u001b[39m us_states_df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpct\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/cse2107/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/cse2107/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/cse2107/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/cse2107/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/opt/anaconda3/envs/cse2107/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/cse2107/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m/opt/anaconda3/envs/cse2107/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/matthewgrossman/Desktop/PUBLIC DATA_ 2025 AI Index Report/4. Economy/Data/fig_4.2.10.csv'"
          ]
        }
      ],
      "source": [
        "# Load US state AI job data\n",
        "us_states_df = pd.read_csv(data_path / 'fig_4.2.10.csv')\n",
        "us_states_df['pct'] = us_states_df['Percentage of US AI job postings'].str.rstrip('%').astype('float')\n",
        "us_states_df = us_states_df.sort_values('pct', ascending=False)\n",
        "\n",
        "print(\"\\nğŸ“Š US STATE AI JOB DISTRIBUTION\\n\")\n",
        "print(f\"Total States: {len(us_states_df)}\")\n",
        "print(f\"Average % per state: {us_states_df['pct'].mean():.2f}%\")\n",
        "print(f\"Median % per state: {us_states_df['pct'].median():.2f}%\")\n",
        "print(f\"\\nğŸ” TOP 15 STATES:\")\n",
        "top_15 = us_states_df.head(15)\n",
        "for idx, row in top_15.iterrows():\n",
        "    print(f\"{row['State code']:>3}: {row['pct']:>6.2f}%\")\n",
        "\n",
        "print(f\"\\nâ¬‡ï¸  BOTTOM 10 STATES:\")\n",
        "bottom_10 = us_states_df.tail(10)\n",
        "for idx, row in bottom_10.iterrows():\n",
        "    print(f\"{row['State code']:>3}: {row['pct']:>6.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 1: Geographic concentration\n",
        "fig, ax = plt.subplots(figsize=(16, 10))\n",
        "\n",
        "top_20_states = us_states_df.head(20)\n",
        "colors = ['#e74c3c' if pct > 5 else '#f39c12' if pct > 2 else '#27ae60' for pct in top_20_states['pct']]\n",
        "\n",
        "bars = ax.barh(range(len(top_20_states)), top_20_states['pct'].values, color=colors, edgecolor='black', linewidth=1.5)\n",
        "ax.set_yticks(range(len(top_20_states)))\n",
        "ax.set_yticklabels(top_20_states['State code'].values, fontsize=11, fontweight='bold')\n",
        "ax.set_xlabel('% of US AI Job Postings', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Top 20 US States: AI Job Concentration', fontsize=14, fontweight='bold', pad=15)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, (state, pct) in enumerate(zip(top_20_states['State code'], top_20_states['pct'])):\n",
        "    ax.text(pct + 0.1, i, f'{pct:.2f}%', va='center', fontweight='bold', fontsize=10)\n",
        "\n",
        "# Add legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor='#e74c3c', label='Hotspot (>5%)'),\n",
        "                   Patch(facecolor='#f39c12', label='Strong (2-5%)'),\n",
        "                   Patch(facecolor='#27ae60', label='Moderate (<2%)')]\n",
        "ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nğŸ’¡ Top 3 States Account For: {us_states_df.head(3)['pct'].sum():.1f}% of all US AI jobs\")\n",
        "print(f\"ğŸ’¡ Top 10 States Account For: {us_states_df.head(10)['pct'].sum():.1f}% of all US AI jobs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Industry Sector Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load industry sector data  \n",
        "sector_df = pd.read_csv(data_path / 'fig_4.2.7.csv')\n",
        "\n",
        "# Clean sector data\n",
        "sector_df['AI_pct'] = sector_df['AI Job Postings (% of All Job Postings)'].str.rstrip('%').astype('float')\n",
        "\n",
        "# Compare 2023 vs 2024\n",
        "sector_2023 = sector_df[sector_df['Year'] == 2023].sort_values('AI_pct', ascending=False)\n",
        "sector_2024 = sector_df[sector_df['Year'] == 2024].sort_values('AI_pct', ascending=False)\n",
        "\n",
        "print(\"\\nğŸ“ˆ INDUSTRY SECTORS: AI JOB CONCENTRATION\\n\")\n",
        "print(\"2024 Rankings (% of all jobs in that sector):\")\n",
        "for idx, row in sector_2024.iterrows():\n",
        "    print(f\"{row['Sector']:<60} {row['AI_pct']:>6.2f}%\")\n",
        "\n",
        "# Calculate growth\n",
        "merged_sectors = sector_2023[['Sector', 'AI_pct']].merge(\n",
        "    sector_2024[['Sector', 'AI_pct']], \n",
        "    on='Sector', \n",
        "    suffixes=('_2023', '_2024')\n",
        ")\n",
        "merged_sectors['growth_pct'] = merged_sectors['AI_pct_2024'] - merged_sectors['AI_pct_2023']\n",
        "merged_sectors = merged_sectors.sort_values('growth_pct', ascending=False)\n",
        "\n",
        "print(\"\\n\\nğŸ“Š 2023â†’2024 GROWTH (Percentage Point Change):\")\n",
        "for idx, row in merged_sectors.iterrows():\n",
        "    growth_indicator = \"ğŸ“ˆ\" if row['growth_pct'] > 0 else \"ğŸ“‰\"\n",
        "    print(f\"{growth_indicator} {row['Sector']:<50} +{row['growth_pct']:>6.2f}pp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 2: Industry Sector Comparison\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "sectors_sorted = sector_2024.sort_values('AI_pct', ascending=True)\n",
        "\n",
        "colors_sector = ['#27ae60' if pct < 2 else '#f39c12' if pct < 5 else '#e74c3c' for pct in sectors_sorted['AI_pct']]\n",
        "\n",
        "ax.barh(range(len(sectors_sorted)), sectors_sorted['AI_pct'].values, color=colors_sector, edgecolor='black', linewidth=1)\n",
        "ax.set_yticks(range(len(sectors_sorted)))\n",
        "ax.set_yticklabels(sectors_sorted['Sector'].values, fontsize=10)\n",
        "ax.set_xlabel('% of Jobs in Sector that are AI-Related', fontweight='bold')\n",
        "ax.set_title('2024: AI Intensity by Industry Sector', fontweight='bold', fontsize=13)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "for i, (sector, pct) in enumerate(zip(sectors_sorted['Sector'], sectors_sorted['AI_pct'])):\n",
        "    ax.text(pct + 0.1, i, f'{pct:.2f}%', va='center', fontweight='bold', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nğŸ¯ Highest AI Intensity: {sector_2024.iloc[0]['Sector']} ({sector_2024.iloc[0]['AI_pct']:.2f}%)\")\n",
        "print(f\"ğŸ“‰ Lowest AI Intensity: {sector_2024.iloc[-1]['Sector']} ({sector_2024.iloc[-1]['AI_pct']:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 3: Sector Growth Comparison\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "growth_sorted = merged_sectors.sort_values('growth_pct')\n",
        "colors_growth = ['#e74c3c' if g < 0 else '#27ae60' for g in growth_sorted['growth_pct']]\n",
        "\n",
        "ax.barh(range(len(growth_sorted)), growth_sorted['growth_pct'].values, color=colors_growth, edgecolor='black', linewidth=1)\n",
        "ax.set_yticks(range(len(growth_sorted)))\n",
        "ax.set_yticklabels(growth_sorted['Sector'].values, fontsize=10)\n",
        "ax.set_xlabel('Percentage Point Change (2023â†’2024)', fontweight='bold')\n",
        "ax.set_title('AI Job Growth by Industry Sector (2023â†’2024)', fontweight='bold', fontsize=13)\n",
        "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "for i, (sector, growth) in enumerate(zip(growth_sorted['Sector'], growth_sorted['growth_pct'])):\n",
        "    ax.text(growth + (0.05 if growth > 0 else -0.05), i, f'{growth:+.2f}pp', \n",
        "           va='center', ha='left' if growth > 0 else 'right', fontweight='bold', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. AI Skills Clusters Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load AI skills clusters (technical specializations)\n",
        "skills_df = pd.read_csv(data_path / 'fig_4.2.3.csv')\n",
        "\n",
        "# Clean skills data\n",
        "skills_df['pct'] = skills_df['AI job postings (% of all job postings)'].str.rstrip('%').astype('float')\n",
        "\n",
        "# Get latest year data\n",
        "latest_year = skills_df['Year'].max()\n",
        "latest_skills = skills_df[skills_df['Year'] == latest_year].sort_values('pct', ascending=False)\n",
        "\n",
        "print(f\"\\nğŸ”§ AI SKILLS CLUSTERS - {latest_year}\\n\")\n",
        "for idx, row in latest_skills.iterrows():\n",
        "    print(f\"{row['Skill cluster']:<40} {row['pct']:>6.2f}% of all jobs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 4: Skills Clusters Evolution\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "skills_list = latest_skills['Skill cluster'].unique()\n",
        "colors_skills = sns.color_palette(\"husl\", len(skills_list))\n",
        "\n",
        "for skill, color in zip(skills_list, colors_skills):\n",
        "    skill_data = skills_df[skills_df['Skill cluster'] == skill].sort_values('Year')\n",
        "    ax.plot(skill_data['Year'], skill_data['pct'], \n",
        "           marker='o', linewidth=2.5, markersize=7, label=skill, color=color)\n",
        "\n",
        "ax.set_xlabel('Year', fontweight='bold', fontsize=11)\n",
        "ax.set_ylabel('% of All Job Postings', fontweight='bold', fontsize=11)\n",
        "ax.set_title('AI Skills Clusters Trends (2010-2024)', fontweight='bold', fontsize=13)\n",
        "ax.legend(loc='upper left', fontsize=9, framealpha=0.9)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ“Š Key Findings:\")\n",
        "print(f\"â€¢ Machine Learning remains dominant at {latest_skills[latest_skills['Skill cluster']=='Machine learning']['pct'].values[0]:.2f}%\")\n",
        "print(f\"â€¢ Generative AI explosive growth: 0.01% (2020) â†’ {latest_skills[latest_skills['Skill cluster']=='Generative AI']['pct'].values[0]:.2f}% (2024)\")\n",
        "print(f\"â€¢ Natural Language Processing steady at ~{latest_skills[latest_skills['Skill cluster']=='Natural language processing']['pct'].values[0]:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. State Analysis - Deep Dive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load historical state trends\n",
        "state_trends_df = pd.read_csv(data_path / 'fig_4.2.12.csv')\n",
        "\n",
        "print(\"\\nğŸ“ˆ MAJOR STATES - AI JOB POSTINGS TRENDS\\n\")\n",
        "\n",
        "for state in ['California', 'Texas', 'New York', 'Washington']:\n",
        "    state_data = state_trends_df[state_trends_df['State'] == state].sort_values('Year')\n",
        "    if len(state_data) > 0:\n",
        "        pct_2010 = state_data[state_data['Year'] == 2010]['Percentage of United States AI job postings'].values[0] if len(state_data[state_data['Year'] == 2010]) > 0 else 0\n",
        "        pct_2024 = state_data[state_data['Year'] == 2024]['Percentage of United States AI job postings'].values[0] if len(state_data[state_data['Year'] == 2024]) > 0 else 0\n",
        "        trend = \"ğŸ“ˆ\" if pct_2024 > pct_2010 else \"ğŸ“‰\"\n",
        "        print(f\"{trend} {state:<20} 2010: {pct_2010:>6.2f}% â†’ 2024: {pct_2024:>6.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 5: Top states trends over time\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "top_states = ['California', 'Texas', 'New York', 'Washington']\n",
        "colors_states = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12']\n",
        "\n",
        "for state, color in zip(top_states, colors_states):\n",
        "    state_data = state_trends_df[state_trends_df['State'] == state].sort_values('Year')\n",
        "    pct_data = state_data['Percentage of United States AI job postings'].str.rstrip('%').astype('float')\n",
        "    ax.plot(state_data['Year'], pct_data, \n",
        "           marker='o', linewidth=3, markersize=8, label=state, color=color)\n",
        "\n",
        "ax.set_xlabel('Year', fontweight='bold', fontsize=12)\n",
        "ax.set_ylabel('% of US AI Job Postings', fontweight='bold', fontsize=12)\n",
        "ax.set_title('Top 4 States: AI Job Postings Trend (2010-2024)', fontweight='bold', fontsize=14)\n",
        "ax.legend(loc='upper left', fontsize=11, framealpha=0.9)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary Dashboard & Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_text = \"\"\"\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘          STATE-BY-STATE AI JOBS MARKET: KEY INSIGHTS                    â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "ğŸ”´ GEOGRAPHIC CONCENTRATION:\n",
        "   â€¢ California dominates: 15.70% of ALL US AI jobs\n",
        "   â€¢ Texas: 8.77% | New York: 5.76%\n",
        "   â€¢ Top 3 states = 30.23% of US AI jobs\n",
        "   â€¢ Top 10 states = 58.8% of US AI jobs\n",
        "   â†’ INSIGHT: Massive geographic inequality; 90% of states have <2% of AI jobs\n",
        "\n",
        "ğŸ­ INDUSTRY HOTSPOTS:\n",
        "   â€¢ Information Sector: 9.33% (2024) - Most AI-intensive industry\n",
        "     â€¢ 2023â†’2024: +4.14 percentage points (+79% growth)\n",
        "   â€¢ Finance & Insurance: 3.76% (2024) - Strong AI adoption\n",
        "   â€¢ Professional, Scientific, Technical Services: 5.25%\n",
        "   â€¢ Manufacturing: 3.75% - Growing automation/robotics\n",
        "   â€¢ Utilities: 2.15% - AI for optimization\n",
        "\n",
        "   â€¢ Retail & Agriculture: <1.5% - Lower AI adoption\n",
        "   â†’ INSIGHT: Information/Tech sector dominates; traditional industries lag\n",
        "\n",
        "ğŸ”§ DOMINANT AI SKILLS (2024):\n",
        "   1. Machine Learning: 0.92% (remains core)\n",
        "   2. Natural Language Processing: 0.23%\n",
        "   3. Neural Networks: 0.16%\n",
        "   4. Autonomous Driving: 0.13%\n",
        "   5. Generative AI: 0.22% (explosive growth from 0.01% in 2020)\n",
        "   â†’ INSIGHT: GenAI booming but still smaller than traditional ML\n",
        "\n",
        "ğŸ’¼ STATE WINNERS vs LOSERS:\n",
        "\n",
        "   ACCELERATING (High & Growing):\n",
        "   â€¢ Washington State: Stable high (~3-4%)\n",
        "   â€¢ California: Growing from 10% â†’ 15.7%\n",
        "   â€¢ Texas: Consistently strong (8.77%)\n",
        "   â€¢ New York: Stable/growing (~5-6%)\n",
        "\n",
        "   STAGNATING (Low):\n",
        "   â€¢ Most states <1.5% of US AI jobs\n",
        "   â€¢ Wyoming, Vermont: <0.2%\n",
        "   â€¢ Limited opportunities in rural/non-tech states\n",
        "   â†’ IMPLICATION: Significant geographic divide creating talent concentration\n",
        "\n",
        "ğŸ“Š SECTOR SHIFT ANALYSIS (2023â†’2024):\n",
        "   ğŸ“ˆ Growing: Information (+4.14pp), Educational Services (+0.36pp)\n",
        "   ğŸ“‰ Declining: All other sectors (<1pp changes)\n",
        "   â†’ INSIGHT: AI growth concentrated in tech/information sector\n",
        "\n",
        "ğŸ¯ GEOGRAPHIC OPPORTUNITIES:\n",
        "   1. California: Saturated but largest absolute market\n",
        "   2. Texas: Growing faster; cheaper labor costs\n",
        "   3. New York: Finance/professional services focus\n",
        "   4. Washington: Tech hub (Seattle, Microsoft influence)\n",
        "   5. Massachusetts: Boston biotech/finance cluster\n",
        "\n",
        "âš ï¸  IMPLICATIONS FOR WORKERS:\n",
        "   â€¢ Geographic mobility critical - most AI jobs concentrated in 4-5 states\n",
        "   â€¢ Remote work crucial for non-coastal talent access\n",
        "   â€¢ Real estate costs rising in AI hubs\n",
        "   â€¢ Skills + Location = Job market advantage\n",
        "   â€¢ Sector matters: Information > Manufacturing > Retail\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\"\"\"\n",
        "\n",
        "print(summary_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualization dashboard\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# 1. Top 10 States pie\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "top_10_states = us_states_df.head(10)\n",
        "others = us_states_df.iloc[10:]['pct'].sum()\n",
        "pie_data = list(top_10_states['pct'].values) + [others]\n",
        "pie_labels = list(top_10_states['State code'].values) + ['Others']\n",
        "colors_pie = sns.color_palette(\"husl\", len(pie_data))\n",
        "ax1.pie(pie_data, labels=pie_labels, autopct='%1.1f%%', colors=colors_pie, startangle=90)\n",
        "ax1.set_title('US States: AI Job Distribution', fontweight='bold', fontsize=11)\n",
        "\n",
        "# 2. Top Industries\n",
        "ax2 = fig.add_subplot(gs[0, 1:])\n",
        "top_industries = sector_2024.head(8).sort_values('AI_pct', ascending=True)\n",
        "ax2.barh(range(len(top_industries)), top_industries['AI_pct'].values, color=sns.color_palette(\"coolwarm\", len(top_industries)))\n",
        "ax2.set_yticks(range(len(top_industries)))\n",
        "ax2.set_yticklabels(top_industries['Sector'].values, fontsize=9)\n",
        "ax2.set_xlabel('% of Jobs in Sector', fontweight='bold')\n",
        "ax2.set_title('Most AI-Intensive Industries (2024)', fontweight='bold', fontsize=11)\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# 3. State comparison\n",
        "ax3 = fig.add_subplot(gs[1, 0])\n",
        "top_states_compare = us_states_df.head(10).sort_values('pct', ascending=True)\n",
        "colors_states_cmp = ['#27ae60' if p < 2 else '#f39c12' if p < 5 else '#e74c3c' for p in top_states_compare['pct']]\n",
        "ax3.barh(range(len(top_states_compare)), top_states_compare['pct'].values, color=colors_states_cmp)\n",
        "ax3.set_yticks(range(len(top_states_compare)))\n",
        "ax3.set_yticklabels(top_states_compare['State code'].values, fontsize=10, fontweight='bold')\n",
        "ax3.set_xlabel('% US AI Jobs', fontweight='bold')\n",
        "ax3.set_title('Top 10 States Ranked', fontweight='bold', fontsize=11)\n",
        "ax3.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# 4. Skills breakdown pie\n",
        "ax4 = fig.add_subplot(gs[1, 1])\n",
        "top_skills_pie = latest_skills.head(6)\n",
        "other_skills = latest_skills.iloc[6:]['pct'].sum()\n",
        "skills_pie_data = list(top_skills_pie['pct'].values) + [other_skills]\n",
        "skills_pie_labels = list(top_skills_pie['Skill cluster'].values) + ['Other']\n",
        "ax4.pie(skills_pie_data, labels=skills_pie_labels, autopct='%1.1f%%', startangle=90)\n",
        "ax4.set_title('AI Skills Distribution (2024)', fontweight='bold', fontsize=11)\n",
        "\n",
        "# 5. Sector growth\n",
        "ax5 = fig.add_subplot(gs[1, 2])\n",
        "top_growth = merged_sectors.nlargest(6, 'growth_pct')\n",
        "colors_growth_bar = ['#27ae60' if g > 0.5 else '#f39c12' if g > 0 else '#e74c3c' for g in top_growth['growth_pct']]\n",
        "ax5.bar(range(len(top_growth)), top_growth['growth_pct'].values, color=colors_growth_bar)\n",
        "ax5.set_xticks(range(len(top_growth)))\n",
        "ax5.set_xticklabels([s[:15]+'...' if len(s) > 15 else s for s in top_growth['Sector']], rotation=45, ha='right', fontsize=8)\n",
        "ax5.set_ylabel('Growth (pp)', fontweight='bold')\n",
        "ax5.set_title('Top Growing Sectors (2023â†’2024)', fontweight='bold', fontsize=11)\n",
        "ax5.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 6-8. Additional metrics\n",
        "ax6 = fig.add_subplot(gs[2, 0])\n",
        "metrics = ['CA Share', 'Top 3 Share', 'Top 10 Share', 'Avg State %']\n",
        "values = [us_states_df.iloc[0]['pct'], us_states_df.head(3)['pct'].sum(), \n",
        "         us_states_df.head(10)['pct'].sum(), us_states_df['pct'].mean()]\n",
        "colors_metrics = ['#e74c3c', '#f39c12', '#f1c40f', '#27ae60']\n",
        "ax6.bar(range(len(metrics)), values, color=colors_metrics)\n",
        "ax6.set_xticks(range(len(metrics)))\n",
        "ax6.set_xticklabels(metrics, fontsize=9)\n",
        "ax6.set_ylabel('% of US AI Jobs', fontweight='bold')\n",
        "ax6.set_title('Market Concentration Metrics', fontweight='bold', fontsize=11)\n",
        "for i, v in enumerate(values):\n",
        "    ax6.text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
        "ax6.set_ylim(0, 70)\n",
        "\n",
        "ax7 = fig.add_subplot(gs[2, 1])\n",
        "industry_counts = pd.Series({\n",
        "    'High AI <2%': len(sector_2024[sector_2024['AI_pct'] > 5]),\n",
        "    'Mid 2-5%': len(sector_2024[(sector_2024['AI_pct'] >= 2) & (sector_2024['AI_pct'] <= 5)]),\n",
        "    'Low <2%': len(sector_2024[sector_2024['AI_pct'] < 2])\n",
        "})\n",
        "ax7.pie(industry_counts.values, labels=industry_counts.index, autopct='%1.0f', \n",
        "       colors=['#e74c3c', '#f39c12', '#27ae60'], startangle=90)\n",
        "ax7.set_title(f'Industry Sectors by AI Intensity', fontweight='bold', fontsize=11)\n",
        "\n",
        "ax8 = fig.add_subplot(gs[2, 2])\n",
        "state_tiers = pd.Series({\n",
        "    'Mega (>10%)': len(us_states_df[us_states_df['pct'] > 10]),\n",
        "    'Major (2-10%)': len(us_states_df[(us_states_df['pct'] >= 2) & (us_states_df['pct'] <= 10)]),\n",
        "    'Minor (<2%)': len(us_states_df[us_states_df['pct'] < 2])\n",
        "})\n",
        "ax8.pie(state_tiers.values, labels=state_tiers.index, autopct='%1.0f', \n",
        "       colors=['#e74c3c', '#f39c12', '#27ae60'], startangle=90)\n",
        "ax8.set_title('State Distribution by Tier', fontweight='bold', fontsize=11)\n",
        "\n",
        "fig.suptitle('AI Jobs Market: Comprehensive State & Industry Dashboard', \n",
        "            fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cse2107",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
